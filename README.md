# Performing_Pyspark


## Application Hellowork
- Création et configuration de projet Spark en utilisant IDE
- Configuration de `Log4J` pour application Spark
- Création et configuration de Spark session
- Gérer les configurations de Spark session en utilisant `spark.conf`
- Création d'une structure modulaire pour application Spark
- Test unitaire pour application Spark
- Construction et package l'application Spark
- Déploiement de l'application Spark sur un Cluster
- Collecter les logs d'application de Spark Cluster

## Application HelloRDD
- Exemple d'un groupby basé sur RDD

## Application HelloSparkSQL
- Création d'une vue global
- Requête SQL sur cette vue global
